{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c1c682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:14:23.884925Z",
     "start_time": "2022-03-27T12:14:19.369163Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794a96e",
   "metadata": {},
   "source": [
    "There is a difference between Preprocessing and EDA (Exploratory data analysis).\n",
    "In Preprocessing, raw data is manipulated to prepare it for further analysis and modeling.\n",
    "in EDA, insights into the data are gained by summarization, visualization and uncovering of relation between the variables ar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888be7dd",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "1. Treatment of missing values\n",
    "2. Remove duplicate rows\n",
    "3. Data format handling\n",
    "4. Remove special characters\n",
    "5. Feature Scaling\n",
    "6. Normalization (optional)\n",
    "7. Binarization  (optional)\n",
    "8. Encoding of categorical variables\n",
    "9. Data binning (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3dea6",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis \n",
    "\n",
    "1. Five point summary\n",
    "2. Correlation\n",
    "3. Data visualization -- boxplot, histograms, scatter plot, bargraphs\n",
    "\n",
    "This could be followed by another preprocessing step --\n",
    "\n",
    "Preprocessing: Treatment of outliers using IQR method and boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfcc6a",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4947691",
   "metadata": {},
   "source": [
    "## 1. Treatment of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df632af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Data Analysis\n",
    "## Treatment of missing values\n",
    "### if a column has > 80% missing values, drop the column\n",
    "### if a row has > 80% missing values, drop the row\n",
    "### otherwise impute the missing values with mean, median, mode\n",
    "### other ways of imputation for missing values:\n",
    "### 0. One could treat missing values as another category in the cate\n",
    "### 1. Imputation by randomly chosen values from the columns itself (variance remains intact)\n",
    "### 2. interpolation, extrapolation based on trends in data\n",
    "### 3. KNN based imputation by considering missing value column as the target column and missing values \n",
    "###    are to be predicted.\n",
    "### 4. imputation by end values, e.g. mean +/- 3*std\n",
    "### 5. Imputation by arbitrary value, usually by low frequent values such as min, max\n",
    "\n",
    "## Code\n",
    "# total        = df.isnull().sum()\n",
    "# percentage   = (df.isnull().sum()/df.isnull.count()).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "##for dropping the columns\n",
    "# df.drop(columns=[])\n",
    "\n",
    "## for imputation of values\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(strategy='median', axis=1) #mean, median, mode\n",
    "# imputer.fit_transform(df)\n",
    "\n",
    "## Treatment of outliers\n",
    "### for numerical variables\n",
    "\n",
    "## code\n",
    "\n",
    "# sns.boxplot(x=df[])\n",
    "# Q1  = df[].quantile(0.25)\n",
    "# Q3  = df[].quantile(0.75)\n",
    "# IQR = Q3-Q1\n",
    "\n",
    "# rcut = Q3 + 1.5*IQR\n",
    "# lcut = Q1 - 1.5*IQR\n",
    "\n",
    "# for outliers, replace them with rcut or lcut as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18a56e",
   "metadata": {},
   "source": [
    "## 2. Remove duplicate rows\n",
    "## 3. Data format handling\n",
    "## 4. Remove special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c705d56",
   "metadata": {},
   "source": [
    "## 5. Scaling\n",
    "#### Guideline: Use RobustScalar as it is not sensitive to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0f471b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:20:36.943055Z",
     "start_time": "2022-09-04T08:20:36.940605Z"
    }
   },
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "## (x-mean)/sd\n",
    "## Transforms the data into standard normal distribution\n",
    "## Not good if the data is not normally distributed \n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# df = read_csv()\n",
    "# df.plot.kde() #kernel density estimate plot\n",
    "# standard_scaler = StandardScaler()\n",
    "# data_tf = standard_scaler.fit_transform(df)\n",
    "# df_tf = pd.DataFrame(data_tf, columns=[])\n",
    "# df_tf.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c586267f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:20:37.133173Z",
     "start_time": "2022-09-04T08:20:37.128762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Min-Max Scaler\n",
    "## (x-min)/(max-min)\n",
    "## transforms the data in [0,1]\n",
    "## Sensitive to outliers\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# minmax_scaler = MinMaxScaler()\n",
    "# data_tf = minmax_scaler.fit_transform(df)\n",
    "# df_tf = pd.DataFrame(data_tf, columns=[])\n",
    "# df_tf.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187affd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:20:37.315880Z",
     "start_time": "2022-09-04T08:20:37.311484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Robust Scaler\n",
    "## (x-Q1)/(Q3-Q1)\n",
    "## Fit for data with outliers\n",
    "\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# robust_scaler = RobustScaler()\n",
    "# data_tf = robust_scaler.fit_transform(df)\n",
    "# df_tf = pd.DataFrame(data_tf, columns=[])\n",
    "# df_tf.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b389308",
   "metadata": {},
   "source": [
    "## 6. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f56f0d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:20:37.679100Z",
     "start_time": "2022-09-04T08:20:37.674696Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "## normalization of a data-point is when each feature is normalizaed w.r.t all the feature values\n",
    "## x/(L2 norm of all of the feature values)\n",
    "## Used mostly in computer vision not in ML\n",
    "\n",
    "# from sklearn.preprocedding import Normalizer\n",
    "\n",
    "# normalizer = Normalizer()\n",
    "# data_tf = normalizer.fit_transform(df)\n",
    "# df_tf = pd.DataFrame(data_tf, columns=[])\n",
    "# ax = plt.axes(projection=3D)\n",
    "# ax.scatter3D(df.x1, df.y1, df.z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977271c7",
   "metadata": {},
   "source": [
    "## 7. Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11512a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:20:38.047832Z",
     "start_time": "2022-09-04T08:20:38.044037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binarization\n",
    "## Threholds the value to binary values\n",
    "## used for target variable\n",
    "\n",
    "# from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# binarizer = Binarizer()\n",
    "# data_tf = binarizer.fit_transform(df)\n",
    "# df_tf = pd.DataFrame(data_tf, columns=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5cf4b",
   "metadata": {},
   "source": [
    "## 8. Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89316807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:20:38.460260Z",
     "start_time": "2022-09-04T08:20:38.457621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "## Categorical variables could be \n",
    "## ordinals (having order), e.g. low, medium, high \n",
    "## OR \n",
    "## nominals e.g. fruit names etc\n",
    "\n",
    "#code\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# df['le_tf'] = df.fit_transform(df[])\n",
    "\n",
    "# ohe = OneHotEncoder()\n",
    "# ohe.fit_transform(df[['le_tf']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
